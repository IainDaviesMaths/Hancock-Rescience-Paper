@ARTICLE{Hancock1991-mp,
  title     = "The principal components of natural images",
  author    = "Hancock, Peter J B and Baddeley, Roland J and Smith, Leslie S",
  abstract  = "A neural net was used to analyse samples of natural images and
               text. For the natural images, components resemble derivatives of
               Gaussian operators, similar to those found in visual cortex and
               inferred from psychophysics. While the results from natural
               images do not depend on scale, those from text images are highly
               scale dependent. Convolution of one of the text components with
               an original image shows that it is sensitive to inter-word gaps.",
  journal   = "Network: Computation in Neural Systems",
  publisher = "Taylor \& Francis",
  volume    =  3,
  number    =  1,
  pages     = "61--70",
  year      =  1991,
}


@ARTICLE{Sanger1989-2cb,
  title    = "Optimal unsupervised learning in a single-layer linear
              feedforward neural network",
  author   = "Sanger, Terence D",
  abstract = "A new approach to unsupervised learning in a single-layer linear
              feedforward neural network is discussed. An optimality principle
              is proposed which is based upon preserving maximal information in
              the output units. An algorithm for unsupervised learning based
              upon a Hebbian learning rule, which achieves the desired
              optimality is presented. The algorithm finds the eigenvectors of
              the input correlation matrix, and it is proven to converge with
              probability one. An implementation which can train neural
              networks using only local ``synaptic'' modification rules is
              described. It is shown that the algorithm is closely related to
              algorithms in statistics (Factor Analysis and Principal
              Components Analysis) and neural networks (Self-supervised
              Backpropagation, or the ``encoder'' problem). It thus provides an
              explanation of certain neural network behavior in terms of
              classical statistical techniques. Examples of the use of a linear
              network for solving image coding and texture segmentation
              problems are presented. Also, it is shown that the algorithm can
              be used to find ``visual receptive fields'' which are
              qualitatively similar to those found in primate retina and visual
              cortex.",
  journal  = "Neural Netw.",
  volume   =  2,
  number   =  6,
  pages    = "459--473",
  month    =  jan,
  year     =  1989,
  keywords = "Neural network; Unsupervised learning; Hebbian learning;
              Feedforward; Karhunen-Loeve Transform; Image coding; Texture;
              Cortical receptive fields",
  issn     = "0893-6080",
  doi      = "10.1016/0893-6080(89)90044-0"
}

@article{Hubel1962-fp,
  title    = "Receptive fields, binocular interaction and functional
              architecture in the cat's visual cortex",
  author   = "Hubel, D H and Wiesel, T N",
  journal  = "J. Physiol.",
  volume   =  160,
  pages    = "106--154",
  month    =  jan,
  year     =  1962,
  keywords = "CEREBRAL CORTEX/physiology",
  issn     = "0022-3751",
  pmid     = "14449617",
  pmc      = "PMC1359523"
}
